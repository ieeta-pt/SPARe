{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagoalmeida/safe_volume/sparse-retrieval/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spare\n",
    "from spare.metadata import MetaDataDocID\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [{\n",
    "        \"id\": \"my first document\",\n",
    "        \"contents\": \"This is my first document in my document collection\"\n",
    "    },{\n",
    "        \"id\": \"my second document\",\n",
    "        \"contents\": \"This is another example of a shorter document\"\n",
    "    }]\n",
    "\n",
    "collection_mapped = map(lambda doc: (doc[\"id\"], doc[\"contents\"]), docs)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bow = spare.BagOfWords(lambda x: tokenizer(x, add_special_tokens=False).input_ids, tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagoalmeida/safe_volume/sparse-retrieval/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Size estimation: 100%|██████████| 2/2 [00:00<00:00, 435.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We estimate that the collection matrix will have density of 0.0003, which requires 1.34e-07 GB. Plus 0.5GB for overheads.\n",
      "Expected number of elements 15 for a shape (2, 30522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "collection = spare.SparseCollection.from_text_iterator(collection_mapped, \n",
    "                                                       text_to_vec=bow,\n",
    "                                                       collection_maxsize=len(docs),\n",
    "                                                       dtype=spare.float32,\n",
    "                                                       backend=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to BM25 weighted collection: 100%|██████████| 2/2 [00:00<00:00, 1158.97it/s]\n"
     ]
    }
   ],
   "source": [
    "collection.transform(spare.BM25Transform(k1=1.2, b=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection is already in BM25 weighting schema, using its parameters\n",
      "Torch convert tensors from CSR to CSC\n",
      "\n",
      "Runner configuration:\n",
      "\n",
      "Hardware\n",
      "  accelerators: ['cpu']\n",
      "  memory per device: 119.76\n",
      "Collection\n",
      "  shape: (2, 30522)\n",
      "  values dtype: spare.float32\n",
      "  indices dtype: spare.int32\n",
      "  memory required: 0.00\n",
      "  memory required (safe margin): 0.00\n",
      "Plan\n",
      "  running mode: Single forward\n",
      "  algorithm: iterative product\n",
      "  objective: performance\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagoalmeida/safe_volume/sparse-retrieval/spare/backend_torch.py:426: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  csc_tensor = torch.sparse_csr_tensor(*sparse_collection.sparse_vecs, sparse_collection.shape).to_sparse_csc()\n"
     ]
    }
   ],
   "source": [
    "sparse_retriver = spare.SparseRetriever(collection, algorithm=\"iterative\", objective=\"performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 387.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval time: 0.008450508117675781 QPS 118.33607944927209\n",
      "Mem transference time: 0.0002300739288330078\n",
      "Time to convert docs ids 0.00019478797912597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RetrievalOutput(ids=array([['my first document', 'my second document']], dtype='<U18'), scores=tensor([[0, 0]], dtype=torch.uint8), timmings=(118.33607944927209, 0.0002300739288330078))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\n",
    "  7820: 1.0,\n",
    "  6254: 1.0,\n",
    "}\n",
    "\n",
    "sparse_retriver.retrieve([question], top_k=10, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From vector\n",
    "collection_mapped = map(lambda doc: (doc[\"id\"], doc[\"contents\"]), docs)\n",
    "bow_docs = list( map(lambda x: (x[0], dict(bow(x[1]))), collection_mapped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size estimation: 100%|██████████| 2/2 [00:00<00:00, 13168.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We estimate that the collection matrix will have density of 0.0003, which requires 1.34e-07 GB. Plus 0.5GB for overheads.\n",
      "Expected number of elements 15 for a shape (2, 30522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "collection = spare.SparseCollection.from_vec_iterator(iter(bow_docs),\n",
    "                                                      vec_dim=bow.dim,\n",
    "                                                       collection_maxsize=len(docs),\n",
    "                                                       dtype=spare.float32,\n",
    "                                                       backend=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size estimation: 100%|██████████| 2/2 [00:00<00:00, 10922.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We estimate that the collection matrix will have density of 0.0003, which requires 1.34e-07 GB. Plus 0.5GB for overheads.\n",
      "Expected number of elements 15 for a shape (2, 30522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7820, 6254, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"shorter document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection is already in BM25 weighting schema, using its parameters\n",
      "Torch convert tensors from CSR to CSC\n",
      "\n",
      "Runner configuration:\n",
      "\n",
      "Hardware\n",
      "  accelerators: ['cpu']\n",
      "  memory per device: 119.76\n",
      "Collection\n",
      "  shape: (2, 30522)\n",
      "  values dtype: spare.float32\n",
      "  indices dtype: spare.int32\n",
      "  memory required: 0.00\n",
      "  memory required (safe margin): 0.00\n",
      "Plan\n",
      "  running mode: Single forward\n",
      "  algorithm: iterative product\n",
      "  objective: performance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_retriver = spare.SparseRetriever(collection, algorithm=\"iterative\", objective=\"performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval time: 0.018156051635742188 QPS 55.07805441748083\n",
      "Mem transference time: 0.0008349418640136719\n",
      "Time to convert docs ids 0.00018835067749023438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RetrievalOutput(ids=array([['my first document', 'my second document']], dtype='<U18'), scores=tensor([[0, 0]], dtype=torch.uint8), timmings=(55.07805441748083, 0.0008349418640136719))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\n",
    "  7820: 1.0,\n",
    "  6254: 1.0,\n",
    "}\n",
    "\n",
    "sparse_retriver.retrieve([question], top_k=10, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-sparse",
   "language": "python",
   "name": "gpu-sparse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
