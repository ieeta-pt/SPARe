{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagoalmeida/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from spare.collection import  SparseCollectionCSR\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"naver/splade-cocondenser-ensembledistil\")\n",
    "token_to_id = tokenizer.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagoalmeida/safe_volume/sparse-retrieval/spare/backend_torch.py:102: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return torch.sparse_csr_tensor(crow_indices, col_indices, values, shape, dtype=self.types_converter[dtype])\n"
     ]
    }
   ],
   "source": [
    "spare_col = SparseCollectionCSR.load_from_file(\"beir_datasets/msmarco/splade_msmarco_index_fp16\")\n",
    "\n",
    "matrix = spare_col.get_sparse_matrix().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "questions_ids = []\n",
    "with open(\"beir_datasets/msmarco/splade_msmarco_questions_bow.jsonl\") as f:\n",
    "    for q in map(json.loads, f):\n",
    "        indices, values = list(zip(*map(lambda x: (token_to_id[x[0]],x[1]),q[\"bow\"].items())))\n",
    "        indices = torch.tensor([indices], dtype=torch.int32)\n",
    "        values = torch.tensor(values, dtype=torch.float16)       \n",
    "        questions.append(torch.sparse_coo_tensor(indices, values.squeeze(0), (matrix.shape[-1],)).to_dense())\n",
    "        questions_ids.append(q[\"docno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m questions:\n\u001b[0;32m----> 4\u001b[0m     q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     r \u001b[39m=\u001b[39m matrix \u001b[39m@\u001b[39m q\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for q in tqdm(questions):\n",
    "    q = q.to(\"cuda\")\n",
    "    r = matrix @ q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, values = list(zip(*map(lambda x: (token_to_id[x[0]],x[1]),questions[0].items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor([indices], dtype=torch.int32)\n",
    "values = torch.tensor(values, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse-retrieval-update",
   "language": "python",
   "name": "sparse-retrieval-update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
